{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njokimainavet/GWAC-PRACTICE/blob/main/DSA_2026_Entry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UrVKLEezfsPw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "03349eba-700b-4824-afff-ef4f25bf01ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'otter'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1363125358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize Otter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!pip install otter-grader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0motter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgrader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0motter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DSA_2026_Entry.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'otter'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Initialize Otter\n",
        "#!pip install otter-grader\n",
        "import otter\n",
        "grader = otter.Notebook(\"DSA_2026_Entry.ipynb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1DroRwx3ENZ"
      },
      "source": [
        "## DSA 2026 Summer School Admittance Check\n",
        "\n",
        "Thanks for your interest in attending DSA Kampala 2026 at Makerere University. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School.\n",
        "Good luck! See you in Kampala at Makerere University!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Upwjh9U3ENa"
      },
      "outputs": [],
      "source": [
        "# Run these once ... Just in case\n",
        "#!pip install otter-grader\n",
        "#!pip install matplotlib scipy  # For machine learning visualization questions\n",
        "import IPython\n",
        "from IPython import get_ipython\n",
        "# Import the good stuff\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "# Note: grader is already initialized in Cell 0 with the notebook path\n",
        "# Don't reinitialize it here, just use the existing grader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mulK0Ir9fsQQ"
      },
      "source": [
        "**The Extra Mile!**\n",
        "\n",
        "This section will test your data analysis skills using real-world economic data from Uganda. You'll work with Consumer Price Index (CPI) data to practice data manipulation, statistical analysis, and time series handling. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_egf664jJMn5"
      },
      "source": [
        "**Question E1:** Load the Uganda Consumer Price Index dataset from the file `data/uganda-consumer-price-index-trends-2020-2023.xlsx` into a pandas dataframe. Display the first 10 rows and the shape of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2lE0yrPJMn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8da362-d71c-464a-e63b-00767abcc87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataframe: Ellipsis\n",
            "\n",
            "First 10 rows:\n",
            "Ellipsis\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Uganda CPI dataset\n",
        "df = ...\n",
        "\n",
        "# Display first 10 rows and shape\n",
        "print(\"Shape of dataframe:\", ...)\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RxzdmJOJ2Yld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b6efdd1c-bb34-4787-dd4a-15197a8f41ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4074947994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"e1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grader' is not defined"
          ]
        }
      ],
      "source": [
        "grader.check(\"e1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er6lemMeJMn5"
      },
      "source": [
        "**Question E2:** Reshape the dataframe from wide format to long format. The monthly columns (dec-20, jan-21, etc.) should become a single 'date' column, and their values should be in a 'value' column. The resulting dataframe should have columns: 'indicator_code', 'description', 'date', and 'value'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQq3JIaVJMn5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Reshape dataframe from wide to long format\n",
        "df_long = ...\n",
        "\n",
        "print(\"Shape after reshaping:\", df_long.shape)\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(df_long.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsEgvYY42Yle"
      },
      "outputs": [],
      "source": [
        "grader.check(\"e2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HM8DysCJMn6"
      },
      "source": [
        "**Question E3:** Convert the 'date' column to datetime format. Handle the date format appropriately (e.g., 'dec-20' should become '2020-12-01', 'jan-21' should become '2021-01-01', etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3NUYMOZJMn6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Convert date column to datetime\n",
        "df_long['date'] = ...\n",
        "\n",
        "print(\"Date column info:\")\n",
        "print(df_long['date'].head(10))\n",
        "print(\"\\nDate range:\", df_long['date'].min(), \"to\", df_long['date'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNY-utIs2Ylf"
      },
      "outputs": [],
      "source": [
        "grader.check(\"e3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAEsAuUvJMn6"
      },
      "source": [
        "**Question E4:** Filter the dataframe to include only CPI indicators (indicator_code starting with 'CPI_'). Create separate dataframes for:\n",
        "- All Items CPI (CPI_16 and CPI_09)\n",
        "- Core CPI (CPI_CORE_16 and CPI_CORE_09)\n",
        "- Food CPI (CPI_FOOD_16 and CPI_FOOD_09)\n",
        "- Energy Fuel and Utilities CPI (CPI_EFU_16 and CPI_EFU_09)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14T6jzZ_JMn6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Filter for CPI indicators\n",
        "df_cpi = ...\n",
        "\n",
        "# Create separate dataframes\n",
        "df_all_items = ...\n",
        "df_core = ...\n",
        "df_food = ...\n",
        "df_efu = ...\n",
        "\n",
        "print(\"All Items CPI shape:\", df_all_items.shape)\n",
        "print(\"Core CPI shape:\", df_core.shape)\n",
        "print(\"Food CPI shape:\", df_food.shape)\n",
        "print(\"EFU CPI shape:\", df_efu.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3SCppXY2Ylg"
      },
      "outputs": [],
      "source": [
        "grader.check(\"e4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWBykh-JMn6"
      },
      "source": [
        "**Question E5:** Check for missing values in the 'value' column. If there are any missing values, replace them with the median value of that specific indicator_code. Display the count of missing values before and after replacement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mQSIPfhJMn6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_before = ...\n",
        "\n",
        "print(\"Missing values before replacement:\", missing_before)\n",
        "\n",
        "# Replace missing values with median per indicator_code\n",
        "df_long['value'] = ...\n",
        "\n",
        "missing_after = ...\n",
        "print(\"Missing values after replacement:\", missing_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESOVg5Dx2Ylh"
      },
      "outputs": [],
      "source": [
        "grader.check(\"e5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7RRkZpnYqa"
      },
      "source": [
        "## Natural Language Processing and Large Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbgK6RQ8nDXw",
        "tags": []
      },
      "source": [
        "**Question N1:** Write a function `count_words` that takes a text string as input and returns a dictionary where keys are unique words (lowercased) and values are their frequencies. Ignore punctuation and split on whitespace.\n",
        "\n",
        "Example: `count_words(\"Hello world hello\")` should return `{'hello': 2, 'world': 1}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6-iwnWSoIDE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def count_words(text):\n",
        "    \"\"\"\n",
        "    Count word frequencies in a text string.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Input text string\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary with words as keys and frequencies as values\n",
        "    \"\"\"\n",
        "    ...\n",
        "    return word_counts\n",
        "\n",
        "# Test the function\n",
        "test_text = \"Data Science Africa 2026 is happening in Kampala at Makerere University. Makerere University is a great place for learning.\"\n",
        "result = count_words(test_text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glty-chQ2Ylr"
      },
      "outputs": [],
      "source": [
        "grader.check(\"n1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc6tiksMqSb0"
      },
      "source": [
        "**Question N2:** Write a function `extract_entities` that takes a text string and a list of entity keywords, and returns a list of sentences that contain any of those keywords. This simulates basic named entity recognition.\n",
        "\n",
        "Example:\n",
        "- Text: \"Makerere University is in Kampala. Kampala is the capital of Uganda.\"\n",
        "- Keywords: [\"Makerere\", \"Kampala\"]\n",
        "- Should return: [\"Makerere University is in Kampala.\", \"Kampala is the capital of Uganda.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWCrhXpKqPJQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def extract_entities(text, keywords):\n",
        "    \"\"\"\n",
        "    Extract sentences containing specified keywords.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Input text string\n",
        "    keywords (list): List of keywords to search for\n",
        "\n",
        "    Returns:\n",
        "    list: List of sentences containing the keywords\n",
        "    \"\"\"\n",
        "    ...\n",
        "    return matching_sentences\n",
        "\n",
        "# Test the function\n",
        "test_text = \"DSA 2026 will be held at Makerere University in Kampala. Kampala is a beautiful city. Makerere University is one of the oldest universities in Africa.\"\n",
        "keywords = [\"Makerere\", \"Kampala\", \"DSA\"]\n",
        "result = extract_entities(test_text, keywords)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXlCYTj92Yls"
      },
      "outputs": [],
      "source": [
        "grader.check(\"n2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke1sfbGu2Yls"
      },
      "source": [
        "**Question N3:** Write a function `calculate_similarity` that takes two text strings and calculates their similarity based on the Jaccard similarity of their word sets. Jaccard similarity is the size of the intersection divided by the size of the union of two sets.\n",
        "\n",
        "Formula: J(A, B) = |A ∩ B| / |A ∪ B|\n",
        "\n",
        "Example:\n",
        "- Text1: \"data science africa\"\n",
        "- Text2: \"data science kampala\"\n",
        "- Should return approximately 0.67 (2 common words / 3 unique words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSmeWPUD2Ylt"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(text1, text2):\n",
        "    \"\"\"\n",
        "    Calculate Jaccard similarity between two text strings.\n",
        "\n",
        "    Parameters:\n",
        "    text1 (str): First text string\n",
        "    text2 (str): Second text string\n",
        "\n",
        "    Returns:\n",
        "    float: Jaccard similarity score between 0 and 1\n",
        "    \"\"\"\n",
        "    ...\n",
        "    return similarity\n",
        "\n",
        "# Test the function\n",
        "text1 = \"Data Science Africa 2026 Kampala Makerere University\"\n",
        "text2 = \"Data Science Africa Kampala Makerere\"\n",
        "similarity = calculate_similarity(text1, text2)\n",
        "print(f\"Similarity: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLEICSu0eMHl"
      },
      "outputs": [],
      "source": [
        "grader.check(\"n3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV92ZtsbeMHl"
      },
      "source": [
        "## Machine Learning and Data Visualization\n",
        "\n",
        "This section introduces you to data visualization and basic machine learning concepts using 2D classification data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgVGnrVXeMHm"
      },
      "source": [
        "**Question M1:** Load the dataset from `data/data-2class.npz`. This file contains a set of 2-dimensional points `d` (shape: 1000x2), and a corresponding set of labels `l` (shape: 1000x1). Create a 2D scatterplot of the points, using red for elements with label 0, and blue for elements with label 1.\n",
        "\n",
        "**Hint:** Use matplotlib for plotting. The dataset keys are 'd' for data points and 'l' for labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooJmqmOYeMHm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = ...\n",
        "\n",
        "# Extract points and labels\n",
        "d = ...\n",
        "l = ...\n",
        "\n",
        "# Create scatterplot\n",
        "# Red for label 0, blue for label 1\n",
        "...\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('2D Scatterplot of Data Points by Class')\n",
        "plt.legend(['Class 0', 'Class 1'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_I8oFU-eMHn"
      },
      "outputs": [],
      "source": [
        "grader.check(\"m1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dr_EqwEeMHn"
      },
      "source": [
        "**Question M2:** Draw a straight line separating the two classes on the scatterplot. The line should visually separate the red points (label 0) from the blue points (label 1). You can choose the line parameters (slope and intercept) manually - the purpose is to think about how this line could be used to classify the data.\n",
        "\n",
        "**Hint:** You can use `plt.plot()` or `plt.axline()` to draw a line. Think about where the line should be positioned to best separate the two classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrNj2KPneMHn"
      },
      "outputs": [],
      "source": [
        "# Recreate the scatterplot\n",
        "...\n",
        "\n",
        "# Draw a separating line\n",
        "# You can choose the line parameters (slope and intercept)\n",
        "# Example: plt.axline((x1, y1), slope=m) or plt.plot([x1, x2], [y1, y2])\n",
        "...\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('2D Scatterplot with Separating Line')\n",
        "plt.legend(['Class 0', 'Class 1', 'Separating Line'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvFq3E8_eMHo"
      },
      "outputs": [],
      "source": [
        "grader.check(\"m2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7wisiVYeMHo"
      },
      "source": [
        "**Question M3:** Fit two 2D Gaussian distributions to the points with label $l_i=0$ and $l_i=1$. For each class, calculate:\n",
        "- The mean (centroid) of the points\n",
        "- The covariance matrix\n",
        "\n",
        "**Hint:** Use NumPy to calculate the mean and covariance. For class 0, filter points where `l == 0`, and for class 1, filter points where `l == 1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwQ7ekwTeMHo"
      },
      "outputs": [],
      "source": [
        "# Filter points by label\n",
        "# Reshape labels if needed: l = l.flatten() or l = l.ravel()\n",
        "points_class_0 = ...\n",
        "points_class_1 = ...\n",
        "\n",
        "# Calculate mean (centroid) for each class\n",
        "mean_class_0 = ...\n",
        "mean_class_1 = ...\n",
        "\n",
        "# Calculate covariance matrix for each class\n",
        "cov_class_0 = ...\n",
        "cov_class_1 = ...\n",
        "\n",
        "print(\"Class 0:\")\n",
        "print(f\"  Mean: {mean_class_0}\")\n",
        "print(f\"  Covariance:\\n{cov_class_0}\")\n",
        "\n",
        "print(\"\\nClass 1:\")\n",
        "print(f\"  Mean: {mean_class_1}\")\n",
        "print(f\"  Covariance:\\n{cov_class_1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlGgrpuseMHo"
      },
      "outputs": [],
      "source": [
        "grader.check(\"m3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lD3PbaYeMHx"
      },
      "source": [
        "**Question M4:** Create a heatmap plotting the two Gaussian distributions and superimpose a scatterplot of the data points.\n",
        "\n",
        "**Hint:**\n",
        "- Use `scipy.stats.multivariate_normal` to create the Gaussian distributions\n",
        "- Create a meshgrid for the heatmap\n",
        "- Use `plt.contour()` or `plt.contourf()` for the heatmap\n",
        "- Overlay the scatterplot on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1wEyBhLeMHy"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Create meshgrid for heatmap\n",
        "x_min, x_max = d[:, 0].min() - 1, d[:, 0].max() + 1\n",
        "y_min, y_max = d[:, 1].min() - 1, d[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Create Gaussian distributions\n",
        "gaussian_class_0 = ...\n",
        "gaussian_class_1 = ...\n",
        "\n",
        "# Calculate probability density for each point in meshgrid\n",
        "pos = np.dstack((xx, yy))\n",
        "pdf_class_0 = ...\n",
        "pdf_class_1 = ...\n",
        "\n",
        "# Create heatmap (contour plot)\n",
        "...\n",
        "\n",
        "# Superimpose scatterplot\n",
        "...\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Gaussian Distributions Heatmap with Data Points')\n",
        "plt.colorbar(label='Probability Density')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmMDpe9NeMHy"
      },
      "outputs": [],
      "source": [
        "grader.check(\"m4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4psDnZalfsQp"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "### Before Submitting:\n",
        "\n",
        "1. **Run all cells in order** - Make sure you've executed every cell from top to bottom. This ensures all your solutions are saved and any outputs are included.\n",
        "\n",
        "2. **Check all tests pass** - Verify that all `grader.check()` cells show that tests pass. If any fail, fix your code and re-run.\n",
        "\n",
        "3. **Save your notebook** - Use File → Save (or Cmd+S / Ctrl+S) to save all your work.\n",
        "\n",
        "4. **Verify your solutions** - Double-check that:\n",
        "   - All `...` placeholders have been replaced with your code\n",
        "   - All functions are properly implemented\n",
        "   - Data analysis questions produce expected outputs\n",
        "   - NLP functions work with the test cases\n",
        "\n",
        "### Submitting:\n",
        "\n",
        "1. **Run the cell below** - This will generate a `.zip` file containing your completed notebook.\n",
        "\n",
        "2. **Find the zip file** - It will be created in the same directory as this notebook, typically named something like `DSA_2026_Entry.zip` or similar.\n",
        "\n",
        "3. **Upload to application portal** - Upload the generated zip file to:\n",
        "   - The Google Sheet link provided in the application instructions, OR\n",
        "   - The application portal/website as specified\n",
        "\n",
        "4. **Keep a backup** - Save a copy of your completed notebook for your records.\n",
        "\n",
        "### Important Reminders:\n",
        "\n",
        "- ⚠️ **All work must be your own** - Uploading work that is not yours will lead to non-admittance to DSA 2026 Kampala at Makerere University.\n",
        "- ✅ Make sure the zip file contains your completed notebook with all solutions\n",
        "- ✅ Do not modify the test files or grader setup\n",
        "- ✅ Include the `data/` folder if required by the submission instructions\n",
        "\n",
        "**Ready to submit? Run the cell below!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AgC1R8vbfsQp"
      },
      "outputs": [],
      "source": [
        "# Save your notebook first, then run this cell to export your submission.grader.export(run_tests=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W8gVwjs4a_f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (TensorFlow)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "otter": {
      "OK_FORMAT": true,
      "tests": {
        "q1": {
          "name": "q1",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_primes(sieve):\n...     assert sieve(30) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n>>> test_primes(sieve)  \n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2": {
          "name": "q2",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_dictionary(Counter):\n...     assert Counter(paragraph) == {' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '’': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '“': 1, '”': 1, '‘': 1, 'E': 1, '/': 1, '\\\\': 1}\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3": {
          "name": "q3",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_keyslist():\n...     assert list(dictionary.keys()) == ['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\']\n>>> test_keyslist() \n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q4": {
          "name": "q4",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_valueslist():\n...     assert list(dictionary.values()) == [3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q5": {
          "name": "q5",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_tuple():\n...     assert final_tuple == (('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n>>> test_tuple() \n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q6": {
          "name": "q6",
          "points": 10,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert_equal(greatest_common_divisor(10, 15), 5)\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q7": {
          "name": "q7",
          "points": 10,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert_equal(get_nearest_farthest((3, 8), [(9, 3), (8,5), (7,6)]), ((7, 6), (9, 3)))\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q8": {
          "name": "q8",
          "points": 5,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert_equal(perfectly_divisible(10,2), [0,2,4,6,8,10])\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q9": {
          "name": "q9",
          "points": 4,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert_equal(flatten_lists([[2,13,44], [6,7]]), [2, 6, 7, 13, 44])\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}